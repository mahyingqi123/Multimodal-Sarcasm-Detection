{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fold 1\n",
      "Fold 1, Epoch 0\n",
      "Loss: 0.6631, Accuracy: 0.5217\n",
      "Precision: 0.4815, Recall: 0.2000, F1: 0.2826\n",
      "Fold 1, Epoch 3\n",
      "Loss: 0.6521, Accuracy: 0.5290\n",
      "Precision: 0.5000, Recall: 0.5231, F1: 0.5113\n",
      "Fold 1, Epoch 4\n",
      "Loss: 0.6499, Accuracy: 0.5580\n",
      "Precision: 0.5333, Recall: 0.4923, F1: 0.5120\n",
      "Fold 1 complete. Best accuracy: 0.5579710144927537 at epoch 4\n",
      " Precision: 0.5333333333333333, Recall: 0.49230769230769234, F1: 0.512\n",
      "Starting fold 2\n",
      "Fold 2, Epoch 0\n",
      "Loss: 0.6425, Accuracy: 0.6232\n",
      "Precision: 0.5952, Recall: 0.7353, F1: 0.6579\n",
      "Fold 2 complete. Best accuracy: 0.6231884057971014 at epoch 0\n",
      " Precision: 0.5952380952380952, Recall: 0.7352941176470589, F1: 0.6578947368421053\n",
      "Starting fold 3\n",
      "Fold 3, Epoch 0\n",
      "Loss: 0.6333, Accuracy: 0.7153\n",
      "Precision: 0.7027, Recall: 0.7536, F1: 0.7273\n",
      "Fold 3 complete. Best accuracy: 0.7153284671532847 at epoch 0\n",
      " Precision: 0.7027027027027027, Recall: 0.7536231884057971, F1: 0.7272727272727273\n",
      "Starting fold 4\n",
      "Fold 4, Epoch 0\n",
      "Loss: 0.6067, Accuracy: 0.6204\n",
      "Precision: 0.6163, Recall: 0.7361, F1: 0.6709\n",
      "Fold 4 complete. Best accuracy: 0.6204379562043796 at epoch 0\n",
      " Precision: 0.6162790697674418, Recall: 0.7361111111111112, F1: 0.6708860759493671\n",
      "Starting fold 5\n",
      "Fold 5, Epoch 0\n",
      "Loss: 0.6114, Accuracy: 0.7299\n",
      "Precision: 0.6824, Recall: 0.8529, F1: 0.7582\n",
      "Fold 5 complete. Best accuracy: 0.7299270072992701 at epoch 0\n",
      " Precision: 0.6823529411764706, Recall: 0.8529411764705882, F1: 0.758169934640523\n",
      "Average metrics\n",
      "Accuracy: 0.6494\n",
      "Precision: 0.6260\n",
      "Recall: 0.7141\n",
      "F1: 0.6652\n"
     ]
    }
   ],
   "source": [
    "# This file is to train the model for sarcasm detection using intermodality inconsistency detection\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class IntermodalityInconsistencyDetector(nn.Module):\n",
    "    def __init__(self, num_emotions=7, embedding_dim=32):\n",
    "        super().__init__()\n",
    "        self.modalities = ['text', 'image', 'audio']\n",
    "        \n",
    "        # Define emotion polarity mapping as a tensor\n",
    "        self.register_buffer('emotion_polarity', torch.tensor([\n",
    "            -0.8,  # angry\n",
    "            -0.7,  # disgust\n",
    "            -0.6,  # fear\n",
    "            0.8,   # happy\n",
    "            -0.5,  # sad\n",
    "            0.3,   # surprise\n",
    "            0.0    # neutral\n",
    "        ], dtype=torch.float32))\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_emotions * 3 + 3, 64),  # 3 modalities * emotions + 3 polarity diffs\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def compute_polarity_mismatch(self, x):\n",
    "        \"\"\"Compute polarity differences between modalities\"\"\"\n",
    "        # Get polarity scores for each modality\n",
    "        polarity_scores = torch.matmul(x, self.emotion_polarity)  # (batch_size, num_modalities)\n",
    "        \n",
    "        # Compute pairwise differences\n",
    "        text_image_diff = torch.abs(polarity_scores[:, 0] - polarity_scores[:, 1])\n",
    "        text_audio_diff = torch.abs(polarity_scores[:, 0] - polarity_scores[:, 2])\n",
    "        image_audio_diff = torch.abs(polarity_scores[:, 1] - polarity_scores[:, 2])\n",
    "        \n",
    "        return torch.stack([text_image_diff, text_audio_diff, image_audio_diff], dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x shape: (batch_size, num_modalities, num_emotions)\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Compute polarity mismatches\n",
    "        polarity_diffs = self.compute_polarity_mismatch(x)\n",
    "        \n",
    "        # Flatten emotion distributions\n",
    "        emotion_features = x.reshape(batch_size, -1)  # Flatten all modalities\n",
    "        \n",
    "        # Concatenate with polarity differences\n",
    "        combined_features = torch.cat([emotion_features, polarity_diffs], dim=1)\n",
    "        \n",
    "        # Get sarcasm prediction\n",
    "        sarcasm_logits = self.classifier(combined_features)\n",
    "        sarcasm_probs = torch.sigmoid(sarcasm_logits)\n",
    "        \n",
    "        return sarcasm_probs, polarity_diffs\n",
    "\n",
    "\n",
    "\n",
    "indices_file = \"split_indices.p\"\n",
    "\n",
    "def pickle_loader(filename):\n",
    "    return pickle.load(open(filename, 'rb'), encoding=\"latin1\")\n",
    "split_indices = pickle_loader(indices_file)\n",
    "# dataset = EmbeddingDataset(data, label_data)\n",
    "device = 'cuda'\n",
    "\n",
    "emotion_to_polarity = {\n",
    "    0: -0.8,    # angry/anger (strong negative)\n",
    "    1: -0.7,    # disgust (strong negative but slightly less than anger)\n",
    "    2: -0.6,    # fear/fearful (negative but less intense than anger/disgust)\n",
    "    3: 0.8,     # happy/joy (strong positive)\n",
    "    4: -0.5,    # sad/sadness (moderate negative)\n",
    "    5: 0.3,     # surprise/surprised (mildly positive - can be positive or negative but often more positive)\n",
    "    6: 0.0      # neutral/calm (middle point)\n",
    "}\n",
    "\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, embedding_dict, label_dict):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embedding_dict: Dictionary with structure \n",
    "                          {\"id\": {\"text\": [0,0,0,0,0,0,1], \n",
    "                                 \"image\": [0,0,0,1,0,0,0],\n",
    "                                 \"audio\": [0,0,0,0,0,0,1]}}\n",
    "            label_dict: Dictionary with structure {\"id\": {\"sarcasm\": label}}\n",
    "        \"\"\"\n",
    "        self.ids = list(embedding_dict.keys())\n",
    "        self.modalities = ['text', 'image', 'audio']\n",
    "        \n",
    "        # Convert one-hot vectors to tensors\n",
    "        self.embeddings = {\n",
    "            mod: [torch.tensor(embedding_dict[id][mod], dtype=torch.float32) \n",
    "                 for id in self.ids]\n",
    "            for mod in self.modalities\n",
    "        }\n",
    "        self.labels = [torch.tensor(label_dict[id]['sarcasm'], dtype=torch.long) \n",
    "                      for id in self.ids]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            {mod: self.embeddings[mod][index] for mod in self.modalities},\n",
    "            self.labels[index]\n",
    "        )\n",
    "\n",
    "def get_dataloader(dataset, indices, batch_size, shuffle):\n",
    "    subset = torch.utils.data.Subset(dataset, indices)\n",
    "    return DataLoader(subset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "def train_epoch(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_embeddings, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Stack modalities\n",
    "        stacked_embeddings = torch.stack(\n",
    "            [batch_embeddings[mod].to(device) for mod in ['text', 'image', 'audio']], \n",
    "            dim=1\n",
    "        )\n",
    "        labels = labels.to(device).float()\n",
    "        \n",
    "        # Forward pass\n",
    "        sarcasm_probs, polarity_diffs = model(stacked_embeddings)\n",
    "        \n",
    "        # Binary cross entropy loss\n",
    "        sarcasm_loss = criterion(sarcasm_probs.squeeze(), labels)\n",
    "        \n",
    "        # Add regularization for polarity differences\n",
    "        polarity_reg = -torch.mean(polarity_diffs * labels.unsqueeze(1)) * 0.1\n",
    "        \n",
    "        # Total loss\n",
    "        loss = sarcasm_loss + polarity_reg\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def validate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    polarity_diffs_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_embeddings, labels in val_loader:\n",
    "            modality_embeddings = {\n",
    "                mod: embeds.to(device) \n",
    "                for mod, embeds in batch_embeddings.items()\n",
    "            }\n",
    "            \n",
    "            stacked_embeddings = torch.stack(\n",
    "                [modality_embeddings[mod] for mod in ['text', 'image', 'audio']], \n",
    "                dim=1\n",
    "            )\n",
    "            \n",
    "            # Get predictions\n",
    "            sarcasm_probs, polarity_diffs = model(stacked_embeddings)\n",
    "            predictions = (sarcasm_probs.squeeze() > 0.5).float()  # Changed for binary classification\n",
    "\n",
    "            labels_np = labels.cpu().numpy()\n",
    "            preds_np = predictions.cpu().numpy()\n",
    "            polarity_np = polarity_diffs.cpu().numpy()\n",
    "            \n",
    "            # If single prediction, convert to array\n",
    "            if np.ndim(preds_np) == 0:\n",
    "                preds_np = np.array([preds_np])\n",
    "            if np.ndim(labels_np) == 0:\n",
    "                labels_np = np.array([labels_np])\n",
    "            \n",
    "            y_true.extend(labels_np)\n",
    "            y_pred.extend(preds_np)\n",
    "            polarity_diffs_list.append(polarity_np)  # Changed from extend to append\n",
    "    \n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    polarity_diffs_array = np.stack(polarity_diffs_list)\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='binary'\n",
    "    )\n",
    "    \n",
    "    return accuracy, precision, recall, f1, polarity_diffs_array\n",
    "\n",
    "def train_model(dataset, split_indices, model, device, batch_size=32):\n",
    "    results = []\n",
    "\n",
    "    \n",
    "    for fold, (train_indices, val_indices) in enumerate(split_indices):\n",
    "        print(f\"Starting fold {fold+1}\")\n",
    "        \n",
    "        train_loader = get_dataloader(dataset, train_indices, batch_size, shuffle=True)\n",
    "        val_loader = get_dataloader(dataset, val_indices, batch_size=1, shuffle=False)\n",
    "        \n",
    "        model = model.to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "        criterion = nn.BCELoss()  # Changed from CrossEntropyLoss\n",
    "        \n",
    "        best_acc = 0\n",
    "        best_epoch = 0\n",
    "        early_stop = 20\n",
    "        epochs = 0\n",
    "        \n",
    "        while True:\n",
    "            # Train epoch\n",
    "            total_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "            \n",
    "            # Validate\n",
    "            accuracy, precision, recall, f1, attention_maps = validate(\n",
    "                model, val_loader, device\n",
    "            )\n",
    "            \n",
    "            # Save best model\n",
    "            if accuracy > best_acc:\n",
    "                print(f'Fold {fold+1}, Epoch {epochs}')\n",
    "                print(f'Loss: {total_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "                print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}')\n",
    "                \n",
    "                best_acc = accuracy\n",
    "                best_precision = precision\n",
    "                best_recall = recall\n",
    "                best_f1 = f1\n",
    "                best_epoch = epochs\n",
    "                \n",
    "                # Save model and attention maps\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.cpu().state_dict(),\n",
    "                    'attention_maps': attention_maps,\n",
    "                    'metrics': {\n",
    "                        'accuracy': accuracy,\n",
    "                        'precision': precision,\n",
    "                        'recall': recall,\n",
    "                        'f1': f1\n",
    "                    }\n",
    "                }, f'model/intermodal_fold_{fold+1}.pt')\n",
    "                \n",
    "                model.to(device)\n",
    "            \n",
    "            # Early stopping\n",
    "            if epochs - best_epoch > early_stop:\n",
    "                break\n",
    "            epochs += 1\n",
    "        \n",
    "        results.append({\n",
    "            'fold': fold + 1,\n",
    "            'best_accuracy': best_acc,\n",
    "            'best_epoch': best_epoch,\n",
    "            'precision': best_precision,\n",
    "            'recall': best_recall,\n",
    "            'f1': best_f1\n",
    "        })\n",
    "        \n",
    "        print(f\"Fold {fold+1} complete. Best accuracy: {best_acc} at epoch {best_epoch}\")\n",
    "        print(f\" Precision: {best_precision}, Recall: {best_recall}, F1: {best_f1}\")\n",
    "    \n",
    "    average = {\n",
    "        'accuracy': np.mean([r['best_accuracy'] for r in results]),\n",
    "        'precision': np.mean([r['precision'] for r in results]),\n",
    "        'recall': np.mean([r['recall'] for r in results]),\n",
    "        'f1': np.mean([r['f1'] for r in results])\n",
    "    }\n",
    "\n",
    "    print(\"Average metrics\")\n",
    "    print(f\"Accuracy: {average['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {average['precision']:.4f}\")\n",
    "    print(f\"Recall: {average['recall']:.4f}\")\n",
    "    print(f\"F1: {average['f1']:.4f}\")\n",
    "\n",
    "\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    data = json.load(open(\"emotion.json\"))\n",
    "    label_data = json.load(open(\"sarcasm_data.json\"))\n",
    "    \n",
    "    # Initialize dataset and model\n",
    "    dataset = MultimodalDataset(data, label_data)\n",
    "    model = IntermodalityInconsistencyDetector(\n",
    "        num_emotions=7,  # Since you have 7 emotion categories\n",
    ")\n",
    "    \n",
    "    # Train model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    results = train_model(dataset, split_indices, model, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
