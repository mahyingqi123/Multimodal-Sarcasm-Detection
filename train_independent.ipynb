{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch import optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model_file = 'text/text_model'\n",
    "visual_model_file = 'visual/visual_model'\n",
    "audio_model_file = 'audio/audio_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.hidden = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "text_data = json.load(open('text_features_clip.json', 'r'))\n",
    "visual_data = json.load(open('video_embeddings_clip.json', 'r'))\n",
    "audio_data = json.load(open('audio_features_wav2vec2_bert.json', 'r'))\n",
    "label_data = json.load(open('sarcasm_data.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, embedding_dict, label_dict):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embedding_dict: A dictionary mapping IDs to embeddings (numpy arrays or lists).\n",
    "            label_dict: A dictionary mapping IDs to labels (integers).\n",
    "        \"\"\"\n",
    "        self.ids = list(embedding_dict.keys())\n",
    "        self.embeddings = [torch.tensor(embedding_dict[id], dtype=torch.float32) for id in self.ids]\n",
    "        self.labels = [torch.tensor(label_dict[id]['sarcasm'], dtype=torch.long) for id in self.ids]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.embeddings[index], self.labels[index]\n",
    "\n",
    "indices_file = \"split_indices.p\"\n",
    "def pickle_loader(filename):\n",
    "    return pickle.load(open(filename, 'rb'), encoding=\"latin1\")\n",
    "split_indices = pickle_loader(indices_file)\n",
    "dataset = EmbeddingDataset(audio_data, label_data)\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fold 1\n",
      "Fold 1, Epoch 0, Loss: 174.33255933225155, Accuracy: 0.6594202898550725\n",
      "Fold 1, Epoch 2, Loss: 148.10255958419293, Accuracy: 0.6811594202898551\n",
      "Fold 1, Epoch 7, Loss: 109.96931778441649, Accuracy: 0.717391304347826\n",
      "Fold 1 complete. Best accuracy: 0.717391304347826 at epoch 7\n",
      "Precision: 0.7032967032967034, Recall: 0.8421052631578947, F1: 0.7664670658682634\n",
      "Starting fold 2\n",
      "Fold 2, Epoch 0, Loss: 179.1945088505745, Accuracy: 0.6739130434782609\n",
      "Fold 2, Epoch 1, Loss: 166.75129691511393, Accuracy: 0.6811594202898551\n",
      "Fold 2, Epoch 2, Loss: 156.2831411100924, Accuracy: 0.7463768115942029\n",
      "Fold 2, Epoch 5, Loss: 139.67985944915563, Accuracy: 0.7536231884057971\n",
      "Fold 2 complete. Best accuracy: 0.7536231884057971 at epoch 5\n",
      "Precision: 0.7216494845360825, Recall: 0.9090909090909091, F1: 0.8045977011494252\n",
      "Starting fold 3\n",
      "Fold 3, Epoch 0, Loss: 177.5731375068426, Accuracy: 0.7007299270072993\n",
      "Fold 3, Epoch 19, Loss: 64.26443411647074, Accuracy: 0.708029197080292\n",
      "Fold 3, Epoch 21, Loss: 51.38691198334482, Accuracy: 0.7153284671532847\n",
      "Fold 3 complete. Best accuracy: 0.7153284671532847 at epoch 21\n",
      "Precision: 0.6857142857142857, Recall: 0.7384615384615385, F1: 0.7111111111111111\n",
      "Starting fold 4\n",
      "Fold 4, Epoch 0, Loss: 180.0488100349903, Accuracy: 0.656934306569343\n",
      "Fold 4, Epoch 2, Loss: 156.00552512332797, Accuracy: 0.7007299270072993\n",
      "Fold 4, Epoch 6, Loss: 128.74589746748097, Accuracy: 0.708029197080292\n",
      "Fold 4, Epoch 13, Loss: 87.33869747412973, Accuracy: 0.7299270072992701\n",
      "Fold 4 complete. Best accuracy: 0.7299270072992701 at epoch 13\n",
      "Precision: 0.7142857142857143, Recall: 0.746268656716418, F1: 0.7299270072992701\n",
      "Starting fold 5\n",
      "Fold 5, Epoch 0, Loss: 175.20883533358574, Accuracy: 0.6204379562043796\n",
      "Fold 5, Epoch 1, Loss: 163.17875745892525, Accuracy: 0.635036496350365\n",
      "Fold 5, Epoch 3, Loss: 147.06590669974685, Accuracy: 0.6423357664233577\n",
      "Fold 5, Epoch 4, Loss: 137.9365917723626, Accuracy: 0.6496350364963503\n",
      "Fold 5, Epoch 6, Loss: 128.71590712782927, Accuracy: 0.7226277372262774\n",
      "Fold 5, Epoch 16, Loss: 77.3287954934367, Accuracy: 0.7299270072992701\n",
      "Fold 5 complete. Best accuracy: 0.7299270072992701 at epoch 16\n",
      "Precision: 0.6666666666666666, Recall: 0.7457627118644068, F1: 0.704\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def get_dataloader(dataset, indices, batch_size, shuffle):\n",
    "    subset = torch.utils.data.Subset(dataset, indices)\n",
    "    return DataLoader(subset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "# Train 5 models for each fold\n",
    "for fold, (train_indices, val_indices) in enumerate(split_indices):\n",
    "    print(f\"Starting fold {fold+1}\")\n",
    "    \n",
    "    train_loader = get_dataloader(dataset, train_indices, batch_size=2, shuffle=True)\n",
    "    val_loader = get_dataloader(dataset, val_indices, batch_size=1, shuffle=False)\n",
    "    \n",
    "    model = SimpleNN(1024, 256, 2).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_epoch = 0\n",
    "    early_stop = 20\n",
    "    epochs = 0\n",
    "    \n",
    "    while True:\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for embeddings, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "            if next(model.parameters()).device != embeddings.device:\n",
    "                model.to(embeddings.device)\n",
    "\n",
    "            outputs = model(embeddings)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        y_true, y_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for embeddings, labels in val_loader:\n",
    "                embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "                outputs = model(embeddings)\n",
    "                predictions = torch.argmax(outputs, dim=1)\n",
    "                y_true.extend(labels.cpu().numpy())\n",
    "                y_pred.extend(predictions.cpu().numpy())\n",
    "        \n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        if accuracy > best_acc:\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "            print(f'Fold {fold+1}, Epoch {epochs}, Loss: {total_loss}, Accuracy: {accuracy}')\n",
    "            best_acc = accuracy\n",
    "            best_epoch = epochs\n",
    "            torch.save(model.cpu().state_dict(), f'model/{audio_model_file}_fold_{fold+1}.pt')\n",
    "        \n",
    "        if epochs - best_epoch > early_stop:\n",
    "            break\n",
    "        epochs += 1\n",
    "\n",
    "    print(f\"Fold {fold+1} complete. Best accuracy: {best_acc} at epoch {best_epoch}\")\n",
    "    print(f\"Precision: {precision}, Recall: {recall}, F1: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fold 1\n",
      "Fold 1, Epoch 0, Loss: 186.1306072473526, Accuracy: 0.5507246376811594\n",
      "Fold 1, Epoch 1, Loss: 149.9215216189623, Accuracy: 0.5797101449275363\n",
      "Fold 1, Epoch 2, Loss: 112.1975835878402, Accuracy: 0.6014492753623188\n",
      "Fold 1, Epoch 6, Loss: 19.448124623376316, Accuracy: 0.6086956521739131\n",
      "Fold 1, Epoch 7, Loss: 12.696646797327048, Accuracy: 0.6304347826086957\n",
      "Fold 1 complete. Best accuracy: 0.6304347826086957 at epoch 7\n",
      "Precision: 0.6060606060606061, Recall: 0.6153846153846154, F1: 0.6106870229007635\n",
      "Starting fold 2\n",
      "Fold 2, Epoch 0, Loss: 188.8181961774826, Accuracy: 0.6231884057971014\n",
      "Fold 2, Epoch 6, Loss: 20.320686713377654, Accuracy: 0.6376811594202898\n",
      "Fold 2, Epoch 9, Loss: 9.732707844786091, Accuracy: 0.644927536231884\n",
      "Fold 2, Epoch 12, Loss: 6.11457789492033, Accuracy: 0.6666666666666666\n",
      "Fold 2 complete. Best accuracy: 0.6666666666666666 at epoch 12\n",
      "Precision: 0.6527777777777778, Recall: 0.6911764705882353, F1: 0.6714285714285714\n",
      "Starting fold 3\n",
      "Fold 3, Epoch 0, Loss: 185.47079548239708, Accuracy: 0.6204379562043796\n",
      "Fold 3, Epoch 1, Loss: 152.3852702975273, Accuracy: 0.6277372262773723\n",
      "Fold 3, Epoch 7, Loss: 6.813776063325349, Accuracy: 0.656934306569343\n",
      "Fold 3, Epoch 8, Loss: 2.859402886620046, Accuracy: 0.6715328467153284\n",
      "Fold 3 complete. Best accuracy: 0.6715328467153284 at epoch 8\n",
      "Precision: 0.7, Recall: 0.6086956521739131, F1: 0.6511627906976744\n",
      "Starting fold 4\n",
      "Fold 4, Epoch 0, Loss: 187.4314098060131, Accuracy: 0.583941605839416\n",
      "Fold 4, Epoch 1, Loss: 147.8332258760929, Accuracy: 0.6058394160583942\n",
      "Fold 4 complete. Best accuracy: 0.6058394160583942 at epoch 1\n",
      "Precision: 0.78125, Recall: 0.3472222222222222, F1: 0.4807692307692307\n",
      "Starting fold 5\n",
      "Fold 5, Epoch 0, Loss: 187.49114313721657, Accuracy: 0.656934306569343\n",
      "Fold 5 complete. Best accuracy: 0.656934306569343 at epoch 0\n",
      "Precision: 0.6438356164383562, Recall: 0.6911764705882353, F1: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "dataset = EmbeddingDataset(text_data, label_data)\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def get_dataloader(dataset, indices, batch_size, shuffle):\n",
    "    subset = torch.utils.data.Subset(dataset, indices)\n",
    "    return DataLoader(subset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "# Train 5 models for each fold\n",
    "for fold, (train_indices, val_indices) in enumerate(split_indices):\n",
    "    print(f\"Starting fold {fold+1}\")\n",
    "    \n",
    "    train_loader = get_dataloader(dataset, train_indices, batch_size=2, shuffle=True)\n",
    "    val_loader = get_dataloader(dataset, val_indices, batch_size=1, shuffle=False)\n",
    "    \n",
    "    model = SimpleNN(512, 256, 2).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_epoch = 0\n",
    "    early_stop = 20\n",
    "    epochs = 0\n",
    "    \n",
    "    while True:\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for embeddings, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "            if next(model.parameters()).device != embeddings.device:\n",
    "                model.to(embeddings.device)\n",
    "\n",
    "            outputs = model(embeddings)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        y_true, y_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for embeddings, labels in val_loader:\n",
    "                embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "                outputs = model(embeddings)\n",
    "                predictions = torch.argmax(outputs, dim=1)\n",
    "                y_true.extend(labels.cpu().numpy())\n",
    "                y_pred.extend(predictions.cpu().numpy())\n",
    "        \n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        if accuracy > best_acc:\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "            print(f'Fold {fold+1}, Epoch {epochs}, Loss: {total_loss}, Accuracy: {accuracy}')\n",
    "            best_acc = accuracy\n",
    "            best_epoch = epochs\n",
    "            torch.save(model.cpu().state_dict(), f'model/{text_model_file}_fold_{fold+1}.pt')\n",
    "        \n",
    "        if epochs - best_epoch > early_stop:\n",
    "            break\n",
    "        epochs += 1\n",
    "\n",
    "    print(f\"Fold {fold+1} complete. Best accuracy: {best_acc} at epoch {best_epoch}\")\n",
    "    print(f\"Precision: {precision}, Recall: {recall}, F1: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fold 1\n",
      "Fold 1, Epoch 0, Loss: 167.65489553660154, Accuracy: 0.6884057971014492\n",
      "Fold 1, Epoch 1, Loss: 143.3527531567961, Accuracy: 0.7028985507246377\n",
      "Fold 1 complete. Best accuracy: 0.7028985507246377 at epoch 1\n",
      "Precision: 0.7160493827160493, Recall: 0.7631578947368421, F1: 0.7388535031847134\n",
      "Starting fold 2\n",
      "Fold 2, Epoch 0, Loss: 171.23269251734018, Accuracy: 0.7101449275362319\n",
      "Fold 2, Epoch 2, Loss: 130.5143204294145, Accuracy: 0.7246376811594203\n",
      "Fold 2, Epoch 3, Loss: 128.88086378760636, Accuracy: 0.7536231884057971\n",
      "Fold 2 complete. Best accuracy: 0.7536231884057971 at epoch 3\n",
      "Precision: 0.8028169014084507, Recall: 0.7402597402597403, F1: 0.7702702702702703\n",
      "Starting fold 3\n",
      "Fold 3, Epoch 0, Loss: 164.1997620910406, Accuracy: 0.7372262773722628\n",
      "Fold 3 complete. Best accuracy: 0.7372262773722628 at epoch 0\n",
      "Precision: 0.7301587301587301, Recall: 0.7076923076923077, F1: 0.7187500000000001\n",
      "Starting fold 4\n",
      "Fold 4, Epoch 0, Loss: 170.82658325880766, Accuracy: 0.6934306569343066\n",
      "Fold 4, Epoch 1, Loss: 146.88319315202534, Accuracy: 0.7007299270072993\n",
      "Fold 4, Epoch 2, Loss: 135.62445344403386, Accuracy: 0.708029197080292\n",
      "Fold 4, Epoch 3, Loss: 126.60849011875689, Accuracy: 0.7664233576642335\n",
      "Fold 4, Epoch 5, Loss: 109.73936300817877, Accuracy: 0.7737226277372263\n",
      "Fold 4 complete. Best accuracy: 0.7737226277372263 at epoch 5\n",
      "Precision: 0.86, Recall: 0.6417910447761194, F1: 0.735042735042735\n",
      "Starting fold 5\n",
      "Fold 5, Epoch 0, Loss: 169.7513494938612, Accuracy: 0.6788321167883211\n",
      "Fold 5, Epoch 1, Loss: 144.35270361974835, Accuracy: 0.6934306569343066\n",
      "Fold 5, Epoch 2, Loss: 136.56019765790552, Accuracy: 0.7226277372262774\n",
      "Fold 5, Epoch 3, Loss: 125.21188784111291, Accuracy: 0.7445255474452555\n",
      "Fold 5, Epoch 4, Loss: 116.39728444162756, Accuracy: 0.7737226277372263\n",
      "Fold 5, Epoch 5, Loss: 102.70895321294665, Accuracy: 0.7956204379562044\n",
      "Fold 5 complete. Best accuracy: 0.7956204379562044 at epoch 5\n",
      "Precision: 0.7123287671232876, Recall: 0.8813559322033898, F1: 0.7878787878787878\n"
     ]
    }
   ],
   "source": [
    "dataset = EmbeddingDataset(visual_data, label_data)\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def get_dataloader(dataset, indices, batch_size, shuffle):\n",
    "    subset = torch.utils.data.Subset(dataset, indices)\n",
    "    return DataLoader(subset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "# Train 5 models for each fold\n",
    "for fold, (train_indices, val_indices) in enumerate(split_indices):\n",
    "    print(f\"Starting fold {fold+1}\")\n",
    "    \n",
    "    train_loader = get_dataloader(dataset, train_indices, batch_size=2, shuffle=True)\n",
    "    val_loader = get_dataloader(dataset, val_indices, batch_size=1, shuffle=False)\n",
    "    \n",
    "    model = SimpleNN(512, 256, 2).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_epoch = 0\n",
    "    early_stop = 20\n",
    "    epochs = 0\n",
    "    \n",
    "    while True:\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for embeddings, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "            if next(model.parameters()).device != embeddings.device:\n",
    "                model.to(embeddings.device)\n",
    "\n",
    "            outputs = model(embeddings)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        y_true, y_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for embeddings, labels in val_loader:\n",
    "                embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "                outputs = model(embeddings)\n",
    "                predictions = torch.argmax(outputs, dim=1)\n",
    "                y_true.extend(labels.cpu().numpy())\n",
    "                y_pred.extend(predictions.cpu().numpy())\n",
    "        \n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        if accuracy > best_acc:\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "            print(f'Fold {fold+1}, Epoch {epochs}, Loss: {total_loss}, Accuracy: {accuracy}')\n",
    "            best_acc = accuracy\n",
    "            best_epoch = epochs\n",
    "            torch.save(model.cpu().state_dict(), f'model/{visual_model_file}_fold_{fold+1}.pt')\n",
    "        \n",
    "        if epochs - best_epoch > early_stop:\n",
    "            break\n",
    "        epochs += 1\n",
    "\n",
    "    print(f\"Fold {fold+1} complete. Best accuracy: {best_acc} at epoch {best_epoch}\")\n",
    "    print(f\"Precision: {precision}, Recall: {recall}, F1: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
